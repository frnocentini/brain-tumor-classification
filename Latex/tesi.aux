\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{italian}{}
\babel@aux{italian}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduzione}{4}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Machine learning e reti neurali}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}L'importanza dell'apprendimento}{5}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neuroni artificiali e deep learning}{8}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Addestramento di una rete}{12}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Overfitting e underfitting}{16}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Classificazione}{18}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Reti neurali convoluzionali}{20}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Ambiente di lavoro}{21}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Python}{21}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Tensorflow e Keras}{21}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Implementazione delle reti e prove sperimentali}{22}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Obiettivo}{22}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}CNN per la rilevazione della polmonite}{23}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Il dataset}{23}{subsection.5.2.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:snap1}{{5.1a}{23}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:snap1}{{a}{23}{\relax }{figure.caption.2}{}}
\newlabel{fig:snap2}{{5.1b}{23}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:snap2}{{b}{23}{\relax }{figure.caption.2}{}}
\newlabel{fig:snap3}{{5.1c}{23}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:snap3}{{c}{23}{\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Si può notare come un soggetto sano (a) mostri polmoni senza aree di anormale opacità. L’immagine (b) è invece un caso di polmonite batterica che presenta il tipico consolidamento. (c) è un caso di polmonite virale che presenta un pattern interstiziale più diffuso in entrambi i polmoni.\relax }}{23}{figure.caption.2}\protected@file@percent }
\newlabel{fig:fig}{{5.1}{23}{Si può notare come un soggetto sano (a) mostri polmoni senza aree di anormale opacità. L’immagine (b) è invece un caso di polmonite batterica che presenta il tipico consolidamento. (c) è un caso di polmonite virale che presenta un pattern interstiziale più diffuso in entrambi i polmoni.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Setup iniziale}{24}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Definizione degli iperparametri}{25}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Definizione e compilazione del modello}{26}{subsection.5.2.4}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.1}Modello in Python utilizzato}{29}{lstlisting.5.1}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.2}Riepilogo del modello. La colonna \lstinline {layer} indica il tipo di strato di cui si tratta. La colonna output mostra la tupla con le dimensioni dello strato in uscita, con una dimensione in più \lstinline {None} che è aggiunta per ospitare la batch size. La terza colonna \lstinline {Param \#} indica il numero di pesi all'interno della rete, i quali possono essere distinti in addestrabili, cioè quelli che vengono aggiornati durante la fase di backpropagation, e quelli per cui questo non vale per motivi di regolarizzazione della rete. Il numero totale di parametri si trova \lstinline {(kernel_height*kernel_width*input_filters*output_filters) + output_filters}. Ad esempio nel primo strato si avra 3*3*32*1+32=320.}{30}{lstlisting.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Creazione dei set di training e validation traminte l’uso dell’image flowing}{31}{subsection.5.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces \small  { Campioni di immagini del dataset di training sui quali sono state aggiunte le tecniche sopra citate. } \relax }}{33}{figure.caption.3}\protected@file@percent }
\newlabel{fi:dcalc}{{5.2}{33}{\small { Campioni di immagini del dataset di training sui quali sono state aggiunte le tecniche sopra citate. } \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.6}Fase di fitting}{33}{subsection.5.2.6}\protected@file@percent }
\newlabel{fig:snap1}{{5.3a}{34}{\relax }{figure.caption.4}{}}
\newlabel{sub@fig:snap1}{{a}{34}{\relax }{figure.caption.4}{}}
\newlabel{fig:snap2}{{5.3b}{34}{\relax }{figure.caption.4}{}}
\newlabel{sub@fig:snap2}{{b}{34}{\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces In entrambe le figure è possibile osservare la curva ROC sul training e sul set di validation. Lo scopo è quello che la curva arancione tenda ad un gradino di ampiezza unitaria.\relax }}{34}{figure.caption.4}\protected@file@percent }
\newlabel{fig:fig}{{5.3}{34}{In entrambe le figure è possibile osservare la curva ROC sul training e sul set di validation. Lo scopo è quello che la curva arancione tenda ad un gradino di ampiezza unitaria.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.7}Predizioni}{34}{subsection.5.2.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces \relax }}{35}{table.caption.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces \relax }}{35}{table.caption.6}\protected@file@percent }
\newlabel{fig:snap1}{{5.4a}{36}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:snap1}{{a}{36}{\relax }{figure.caption.7}{}}
\newlabel{fig:snap2}{{5.4b}{36}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:snap2}{{b}{36}{\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces  Matrici di confusione ottenute. (a) è la matrice di confusione del modello con il set di training lasciato come l'originale. Si può vedere che vi sono molti errori nel prevedere il soggetto sano.   (b) è la matrice di confusione con il set di training modificato come nella Figura 5.2. In questo caso vi sono pochissimi errori di predizione. \relax }}{36}{figure.caption.7}\protected@file@percent }
\newlabel{fig:fig}{{5.4}{36}{Matrici di confusione ottenute. (a) è la matrice di confusione del modello con il set di training lasciato come l'originale. Si può vedere che vi sono molti errori nel prevedere il soggetto sano. \\ (b) è la matrice di confusione con il set di training modificato come nella Figura 5.2. In questo caso vi sono pochissimi errori di predizione. \relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces \small  {Dimostrazione di alcune previsioni. } \relax }}{37}{figure.caption.8}\protected@file@percent }
\newlabel{fi:dcalc}{{5.5}{37}{\small {Dimostrazione di alcune previsioni. } \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.8}Considerazioni finali}{37}{subsection.5.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}CNN per la classificazione di risonanze magnetiche cerebrali}{39}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusioni}{40}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{ieeetr}
\bibdata{bibliografia}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Codice}{41}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\gdef \@abspage@last{42}
