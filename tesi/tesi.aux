\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{italian}{}
\babel@aux{italian}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduzione}{4}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{ann}
\citation{learning}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Machine learning e reti neurali}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}L'importanza dell'apprendimento}{6}{section.2.1}\protected@file@percent }
\citation{ml}
\citation{class}
\citation{prob}
\citation{img_learning}
\citation{img_learning}
\citation{reti}
\citation{neuron}
\citation{neuron}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces \small  {Schema dell' apprendimento supervisionato~\cite  {img_learning}. } \relax }}{9}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fi:dcalc}{{2.1}{9}{\small {Schema dell' apprendimento supervisionato~\cite {img_learning}. } \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neuroni artificiali e deep learning}{9}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces \small  {Un semplice schema di neurone. ~\cite  {neuron} } \relax }}{10}{figure.caption.3}\protected@file@percent }
\newlabel{fi:dcalc}{{2.2}{10}{\small {Un semplice schema di neurone. ~\cite {neuron} } \relax }{figure.caption.3}{}}
\citation{reti}
\citation{reti}
\newlabel{1}{{2.1}{11}{Neuroni artificiali e deep learning}{equation.2.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces \small  {Schema di un percettrone. ~\cite  {reti} } \relax }}{11}{figure.caption.4}\protected@file@percent }
\newlabel{fi:dcalc}{{2.3}{11}{\small {Schema di un percettrone. ~\cite {reti} } \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces \small  {Figura che rappresenta come le reti neurali siano effettivamente ispirate alle reti neurali biologiche. A sinistra vi è una rete di neuroni reali e a destra un modello di percettrone. } \relax }}{12}{figure.caption.5}\protected@file@percent }
\newlabel{fi:dcalc}{{2.4}{12}{\small {Figura che rappresenta come le reti neurali siano effettivamente ispirate alle reti neurali biologiche. A sinistra vi è una rete di neuroni reali e a destra un modello di percettrone. } \relax }{figure.caption.5}{}}
\citation{dl}
\citation{dim}
\citation{dnn}
\citation{dnn}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces \small  {Esempio di rete neurale profonda con 3 strati nascosti.~\cite  {dnn}} \relax }}{14}{figure.caption.6}\protected@file@percent }
\newlabel{fi:dcalc}{{2.5}{14}{\small {Esempio di rete neurale profonda con 3 strati nascosti.~\cite {dnn}} \relax }{figure.caption.6}{}}
\citation{tesi}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Addestramento di una rete}{16}{section.2.3}\protected@file@percent }
\citation{ann}
\newlabel{2}{{2.2}{17}{Addestramento di una rete}{equation.2.3.2}{}}
\newlabel{3}{{2.3}{18}{Addestramento di una rete}{equation.2.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Overfitting e underfitting}{20}{section.2.4}\protected@file@percent }
\citation{ofuf}
\citation{ofuf}
\citation{classdef}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces \small  {I grafici mostrano cosa significa underfitting e overfitting in maniera visiva.~\cite  {ofuf} Si può vedere come la prima curva di regressione non vada a suddividere in maniera precisa i dati in rosso, mentre l'ultima curva separi bene tutti i dati classificandoli, ma è una curva troppo precisa e specifica per i dati di interesse e che probabilmente non andrà a dare risultati corretti se i dati in ingresso si discostano anche leggermente da quelli rossi in figura. Al centro invece la curva risulta essere bilanciata. } \relax }}{22}{figure.caption.7}\protected@file@percent }
\newlabel{fi:dcalc}{{2.6}{22}{\small {I grafici mostrano cosa significa underfitting e overfitting in maniera visiva.~\cite {ofuf} Si può vedere come la prima curva di regressione non vada a suddividere in maniera precisa i dati in rosso, mentre l'ultima curva separi bene tutti i dati classificandoli, ma è una curva troppo precisa e specifica per i dati di interesse e che probabilmente non andrà a dare risultati corretti se i dati in ingresso si discostano anche leggermente da quelli rossi in figura. Al centro invece la curva risulta essere bilanciata. } \relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Classificazione}{22}{section.2.5}\protected@file@percent }
\citation{reti}
\citation{cnn}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Reti neurali convoluzionali}{25}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Funzionamento generale}{25}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Architettura generale di una CNN}{26}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Convoluzione}{26}{subsection.3.2.1}\protected@file@percent }
\citation{feature}
\citation{feature}
\citation{sparse}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \small  {Questo kernel è in grado di identificare i bordi della sagoma dell'animale nell'immagine tramite una precisa disposizione dei valori dei pesi nella matrice stessa.~\cite  {feature}} \relax }}{27}{figure.caption.8}\protected@file@percent }
\newlabel{fi:dcalc}{{3.1}{27}{\small {Questo kernel è in grado di identificare i bordi della sagoma dell'animale nell'immagine tramite una precisa disposizione dei valori dei pesi nella matrice stessa.~\cite {feature}} \relax }{figure.caption.8}{}}
\citation{max-pool}
\citation{reti}
\citation{reti}
\citation{cnn}
\citation{cnn}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces \small  {Rappresentazione schematica di una CNN. Da sinistra verso destra: uno strato di input, le feature maps ottenute con la convoluzione, gli strati di max-pooling e infine la parte completamente connessa.~\cite  {reti} } \relax }}{29}{figure.caption.9}\protected@file@percent }
\newlabel{fi:dcalc}{{3.2}{29}{\small {Rappresentazione schematica di una CNN. Da sinistra verso destra: uno strato di input, le feature maps ottenute con la convoluzione, gli strati di max-pooling e infine la parte completamente connessa.~\cite {reti} } \relax }{figure.caption.9}{}}
\citation{tesi}
\citation{tesi}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces \small  { Schema di come avviene la convoluzione.~\cite  {cnn} } \relax }}{30}{figure.caption.10}\protected@file@percent }
\newlabel{fi:dcalc}{{3.3}{30}{\small { Schema di come avviene la convoluzione.~\cite {cnn} } \relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Padding}{30}{subsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces \small  { Schema dei vari tipi di padding. A sinistra il padding di tipo \emph  {full}, al centro quello di tipo \emph  {same}, a destra il padding \emph  {valid}~\cite  {tesi} } \relax }}{30}{figure.caption.11}\protected@file@percent }
\newlabel{fi:dcalc}{{3.4}{30}{\small { Schema dei vari tipi di padding. A sinistra il padding di tipo \emph {full}, al centro quello di tipo \emph {same}, a destra il padding \emph {valid}~\cite {tesi} } \relax }{figure.caption.11}{}}
\citation{grad}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Funzioni di attivazione}{31}{subsection.3.2.3}\protected@file@percent }
\citation{cnn2}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Strati di subsampling: Pooling Layers}{32}{subsection.3.2.4}\protected@file@percent }
\citation{cnn2}
\citation{cnn2}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces \small  { Esempio di pooling tramite una pool 2x2. ~\cite  {cnn2} } \relax }}{33}{figure.caption.12}\protected@file@percent }
\newlabel{fi:dcalc}{{3.5}{33}{\small { Esempio di pooling tramite una pool 2x2. ~\cite {cnn2} } \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Fully connected layers}{33}{subsection.3.2.5}\protected@file@percent }
\citation{lib}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Ambiente di lavoro}{35}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Python}{35}{section.4.1}\protected@file@percent }
\citation{keras}
\citation{tf}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Tensorflow e Keras}{36}{section.4.2}\protected@file@percent }
\citation{jn}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Jupyter notebook e GoogleCollab}{37}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Implementazione delle reti e prove sperimentali}{39}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Obiettivo}{39}{section.5.1}\protected@file@percent }
\citation{dspneum}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}CNN per la rilevazione della polmonite}{40}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Il dataset}{40}{subsection.5.2.1}\protected@file@percent }
\newlabel{fig:snap1}{{5.1a}{40}{\relax }{figure.caption.13}{}}
\newlabel{sub@fig:snap1}{{a}{40}{\relax }{figure.caption.13}{}}
\newlabel{fig:snap2}{{5.1b}{40}{\relax }{figure.caption.13}{}}
\newlabel{sub@fig:snap2}{{b}{40}{\relax }{figure.caption.13}{}}
\newlabel{fig:snap3}{{5.1c}{40}{\relax }{figure.caption.13}{}}
\newlabel{sub@fig:snap3}{{c}{40}{\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Si può notare come un soggetto sano (a) mostri polmoni senza aree di anormale opacità. L’immagine (b) è invece un caso di polmonite batterica che presenta il tipico consolidamento. (c) è un caso di polmonite virale che presenta un un'opacità interstiziale più diffusa in entrambi i polmoni.\relax }}{40}{figure.caption.13}\protected@file@percent }
\newlabel{fig:fig}{{5.1}{40}{Si può notare come un soggetto sano (a) mostri polmoni senza aree di anormale opacità. L’immagine (b) è invece un caso di polmonite batterica che presenta il tipico consolidamento. (c) è un caso di polmonite virale che presenta un un'opacità interstiziale più diffusa in entrambi i polmoni.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Setup iniziale}{41}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Definizione degli iperparametri}{42}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Definizione e compilazione del modello}{44}{subsection.5.2.4}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.1}Modello in Python utilizzato}{45}{lstlisting.5.1}\protected@file@percent }
\citation{augpneum}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.2}Riepilogo del modello utilizzato se in input vi è un immagine con \lstinline {image_size} pari a 600. La colonna \lstinline {layer} indica il tipo di strato di cui si tratta. La colonna output mostra la tupla con le dimensioni dello strato in uscita (vedasi sezione 3.2.2 e 3.2.3 per calcolarlo), con una dimensione in più \lstinline {None} che è aggiunta per ospitare la batch size. La terza colonna \lstinline {Param \#} indica il numero di pesi all'interno della rete, i quali possono essere distinti in addestrabili, cioè quelli che vengono aggiornati durante la fase di backpropagation, e quelli per cui questo non vale per motivi di regolarizzazione della rete. Il numero totale di parametri si trova \lstinline {(kernel_height*kernel_width*input_filters+bias)* output_filters}. Ad esempio nel primo strato si avra 3*3*32*1+32=320, in quanto il valore del bias è 1 di default}{47}{lstlisting.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Creazione dei set di training e validation traminte l’uso dell’image flowing}{47}{subsection.5.2.5}\protected@file@percent }
\citation{tesi}
\citation{tesi}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces \small  { Campioni di immagini del dataset di training sui quali sono state aggiunte le tecniche sopra citate. Immagine tratta dal codice (vedasi capitolo 7). } \relax }}{50}{figure.caption.14}\protected@file@percent }
\newlabel{fi:dcalc}{{5.2}{50}{\small { Campioni di immagini del dataset di training sui quali sono state aggiunte le tecniche sopra citate. Immagine tratta dal codice (vedasi capitolo 7). } \relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.6}Fase di fitting}{50}{subsection.5.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces \small  {Si vede come si va in overfitting quando l'errore di validation è molto maggiore di quello di training all'aumentare delle epoche, mentre in underfitting si va quando non si hanno sufficienti parametri per allenare il modello.\cite  {tesi} } \relax }}{51}{figure.caption.15}\protected@file@percent }
\newlabel{fi:dcalc}{{5.3}{51}{\small {Si vede come si va in overfitting quando l'errore di validation è molto maggiore di quello di training all'aumentare delle epoche, mentre in underfitting si va quando non si hanno sufficienti parametri per allenare il modello.\cite {tesi} } \relax }{figure.caption.15}{}}
\newlabel{fig:snap1}{{5.4a}{52}{\relax }{figure.caption.16}{}}
\newlabel{sub@fig:snap1}{{a}{52}{\relax }{figure.caption.16}{}}
\newlabel{fig:snap2}{{5.4b}{52}{\relax }{figure.caption.16}{}}
\newlabel{sub@fig:snap2}{{b}{52}{\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces In entrambe le figure è possibile osservare le curve che rappresentano accuracy e loss rispettivamente per training e sul set di validation nei due casi. (a) si riferisce al set di training originale, (b) al set di training modificato come nella figura 5.2. Si vede che nel primo caso la funzione di perdita è più alta del secondo caso. Le figure sono state create con la libreria Pandas (codice capitolo 7). Il numero di epoche tra le due immagini è diverso perchè nel primo caso la funzione \lstinline {EarlyStopping} ha fermato il training alla undicesima epoca, nel secondo alla quindicesima.\relax }}{52}{figure.caption.16}\protected@file@percent }
\newlabel{fig:fig}{{5.4}{52}{In entrambe le figure è possibile osservare le curve che rappresentano accuracy e loss rispettivamente per training e sul set di validation nei due casi. (a) si riferisce al set di training originale, (b) al set di training modificato come nella figura 5.2. Si vede che nel primo caso la funzione di perdita è più alta del secondo caso. Le figure sono state create con la libreria Pandas (codice capitolo 7). Il numero di epoche tra le due immagini è diverso perchè nel primo caso la funzione \lstinline {EarlyStopping} ha fermato il training alla undicesima epoca, nel secondo alla quindicesima.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.7}Predizioni e grafici}{52}{subsection.5.2.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Classification report per il modello con il set mantenuto come l'originale.\relax }}{53}{table.caption.17}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Classification report per il modello con il set ampliato.\relax }}{53}{table.caption.18}\protected@file@percent }
\newlabel{fig:snap1}{{5.5a}{54}{\relax }{figure.caption.19}{}}
\newlabel{sub@fig:snap1}{{a}{54}{\relax }{figure.caption.19}{}}
\newlabel{fig:snap2}{{5.5b}{54}{\relax }{figure.caption.19}{}}
\newlabel{sub@fig:snap2}{{b}{54}{\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces  Matrici di confusione ottenute. (a) è la matrice di confusione del modello con il set di training lasciato come l'originale. Si può vedere che vi sono molti errori nel prevedere il soggetto sano.   (b) è la matrice di confusione con il set di training modificato come nella Figura 5.2. In questo caso vi sono pochissimi errori di predizione. \relax }}{54}{figure.caption.19}\protected@file@percent }
\newlabel{fig:fig}{{5.5}{54}{Matrici di confusione ottenute. (a) è la matrice di confusione del modello con il set di training lasciato come l'originale. Si può vedere che vi sono molti errori nel prevedere il soggetto sano. \\ (b) è la matrice di confusione con il set di training modificato come nella Figura 5.2. In questo caso vi sono pochissimi errori di predizione. \relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces \small  {Dimostrazione di alcune previsioni sul set della polmonite del sistema allenato con testin accuracy media del 93.75$\%$. (Codice nel capitolo 7). } \relax }}{55}{figure.caption.20}\protected@file@percent }
\newlabel{fi:dcalc}{{5.6}{55}{\small {Dimostrazione di alcune previsioni sul set della polmonite del sistema allenato con testin accuracy media del 93.75$\%$. (Codice nel capitolo 7). } \relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.8}Considerazioni finali}{55}{subsection.5.2.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces La tabella mostra come i parametri della terza riga abbiano portato ai migliori risultati.\relax }}{56}{table.caption.21}\protected@file@percent }
\citation{dsbrain}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}CNN per la classificazione di risonanze magnetiche cerebrali}{57}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Il dataset}{57}{subsection.5.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces \small  {Campione di risonanza magnetica per ognuna delle diagnosi. (Disponibile codice in sezione 7) } \relax }}{58}{figure.caption.22}\protected@file@percent }
\newlabel{fi:dcalc}{{5.7}{58}{\small {Campione di risonanza magnetica per ognuna delle diagnosi. (Disponibile codice in sezione 7) } \relax }{figure.caption.22}{}}
\citation{dropout}
\citation{dropout}
\citation{dropout}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Setup iniziale}{59}{subsection.5.3.2}\protected@file@percent }
\citation{norm}
\citation{alexnet}
\citation{effnet}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces \small  {Dimostrazione schematica di cosa fa il dropout~\cite  {dropout}. La prima immagine rappresenta una rete neurale connessa senza dropout, mentre la seconda rappresenta la rete dopo il dropout. . } \relax }}{60}{figure.caption.23}\protected@file@percent }
\newlabel{fi:dcalc}{{5.8}{60}{\small {Dimostrazione schematica di cosa fa il dropout~\cite {dropout}. La prima immagine rappresenta una rete neurale connessa senza dropout, mentre la seconda rappresenta la rete dopo il dropout. . } \relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Definizione degli iperparametri e dei modelli utilizzati}{60}{subsection.5.3.3}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.3}Codice Python del primo modello utilizzato.}{63}{lstlisting.5.3}\protected@file@percent }
\citation{alexnet}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces \small  {schema di Alexnet riadattato, realizzato con NNSVG.} \relax }}{64}{figure.caption.24}\protected@file@percent }
\newlabel{fi:dcalc}{{5.9}{64}{\small {schema di Alexnet riadattato, realizzato con NNSVG.} \relax }{figure.caption.24}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.4}Codice Python del modello di AlexNet riadattato.}{65}{lstlisting.5.4}\protected@file@percent }
\citation{mobilenet}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces \small  {Immagine presa dal paper di EfficientNet. Essa mostra come è fatta l'architettura di EfficientNetB0. Ogni riga descrive un passaggio i con un numero \emph  {$L_i$} di strati, con risoluzione in input pari a $H_i$ x $W_i$ e numero di filtri in output pari a $C_i$. Si sfrutta uno strato di convoluzione seguito da 7 blocchi di MBConv (vedasi sotto) e che termina con uno strato FC. } \relax }}{66}{figure.caption.25}\protected@file@percent }
\newlabel{fi:dcalc}{{5.10}{66}{\small {Immagine presa dal paper di EfficientNet. Essa mostra come è fatta l'architettura di EfficientNetB0. Ogni riga descrive un passaggio i con un numero \emph {$L_i$} di strati, con risoluzione in input pari a $H_i$ x $W_i$ e numero di filtri in output pari a $C_i$. Si sfrutta uno strato di convoluzione seguito da 7 blocchi di MBConv (vedasi sotto) e che termina con uno strato FC. } \relax }{figure.caption.25}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.5}Codice realizzato per applicare il Trasfer Learning.}{67}{lstlisting.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Creazione dei set di training e testing}{68}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}Fase di fitting e predizioni}{69}{subsection.5.3.5}\protected@file@percent }
\citation{gaussnoise}
\newlabel{fig:snap1}{{5.11a}{70}{\relax }{figure.caption.26}{}}
\newlabel{sub@fig:snap1}{{a}{70}{\relax }{figure.caption.26}{}}
\newlabel{fig:snap2}{{5.11b}{70}{\relax }{figure.caption.26}{}}
\newlabel{sub@fig:snap2}{{b}{70}{\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Esempi di andamento della validation e training accuracy-loss nel training del modello 1. A sinistra il training fatto sul set originale, a destra quello fatto sul set alterato Come si vede nella figura (b) il set alterato non comporta miglioramenti in fase di testing e con le epoche cresce anche l'errore di stima.\relax }}{70}{figure.caption.26}\protected@file@percent }
\newlabel{fig:fig}{{5.11}{70}{Esempi di andamento della validation e training accuracy-loss nel training del modello 1. A sinistra il training fatto sul set originale, a destra quello fatto sul set alterato Come si vede nella figura (b) il set alterato non comporta miglioramenti in fase di testing e con le epoche cresce anche l'errore di stima.\relax }{figure.caption.26}{}}
\newlabel{fig:snap1}{{5.12a}{71}{\relax }{figure.caption.27}{}}
\newlabel{sub@fig:snap1}{{a}{71}{\relax }{figure.caption.27}{}}
\newlabel{fig:snap2}{{5.12b}{71}{\relax }{figure.caption.27}{}}
\newlabel{sub@fig:snap2}{{b}{71}{\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Esempi di RM prima di aver applicato il rumore gaussiano (a) e dopo (b). In questo caso la varianza è stata posta pari a 20 volutamente esagerando per dare maggior idea di che cosa comporta, ma in generale si utilizza un valore più basso per non alterare troppo le immagini.\relax }}{71}{figure.caption.27}\protected@file@percent }
\newlabel{fig:fig}{{5.12}{71}{Esempi di RM prima di aver applicato il rumore gaussiano (a) e dopo (b). In questo caso la varianza è stata posta pari a 20 volutamente esagerando per dare maggior idea di che cosa comporta, ma in generale si utilizza un valore più basso per non alterare troppo le immagini.\relax }{figure.caption.27}{}}
\newlabel{fig:snap1}{{5.13a}{72}{\relax }{figure.caption.28}{}}
\newlabel{sub@fig:snap1}{{a}{72}{\relax }{figure.caption.28}{}}
\newlabel{fig:snap2}{{5.13b}{72}{\relax }{figure.caption.28}{}}
\newlabel{sub@fig:snap2}{{b}{72}{\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Esempi di andamento della validation e training accuracy-loss del secondo modello. A sinistra il training fatto sul set originale, a destra quello fatto sul set alterato con il rumore gaussiano. \relax }}{72}{figure.caption.28}\protected@file@percent }
\newlabel{fig:fig}{{5.13}{72}{Esempi di andamento della validation e training accuracy-loss del secondo modello. A sinistra il training fatto sul set originale, a destra quello fatto sul set alterato con il rumore gaussiano. \relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces \small  {Andamento della training-validation accuracy e loss del modello 3.} \relax }}{73}{figure.caption.29}\protected@file@percent }
\newlabel{fi:dcalc}{{5.14}{73}{\small {Andamento della training-validation accuracy e loss del modello 3.} \relax }{figure.caption.29}{}}
\newlabel{fig:snap1}{{5.15a}{74}{\relax }{figure.caption.30}{}}
\newlabel{sub@fig:snap1}{{a}{74}{\relax }{figure.caption.30}{}}
\newlabel{fig:snap2}{{5.15b}{74}{\relax }{figure.caption.30}{}}
\newlabel{sub@fig:snap2}{{b}{74}{\relax }{figure.caption.30}{}}
\newlabel{fig:snap3}{{5.15c}{74}{\relax }{figure.caption.30}{}}
\newlabel{sub@fig:snap3}{{c}{74}{\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces 3 matrici di confusione del primo modello (a), di AlexNet (b) (set a cui è stato applicato il rumore) e di Efficient-Net (c) pre-addestrato. Nella diagonale superiore vi sono i falsi positivi e in quella inferiore i falsi negativi. Si può notare che i falsi negativi diminuiscono a mano a mano che il sistema è più accurato.\relax }}{74}{figure.caption.30}\protected@file@percent }
\newlabel{fig:fig}{{5.15}{74}{3 matrici di confusione del primo modello (a), di AlexNet (b) (set a cui è stato applicato il rumore) e di Efficient-Net (c) pre-addestrato. Nella diagonale superiore vi sono i falsi positivi e in quella inferiore i falsi negativi. Si può notare che i falsi negativi diminuiscono a mano a mano che il sistema è più accurato.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces \small  {Predizioni fatte dal modello con associata la relativa probabilità versus quelle effettive su un insieme di immagini (codice di realizzazione nel capitolo 7). } \relax }}{75}{figure.caption.31}\protected@file@percent }
\newlabel{fi:dcalc}{{5.16}{75}{\small {Predizioni fatte dal modello con associata la relativa probabilità versus quelle effettive su un insieme di immagini (codice di realizzazione nel capitolo 7). } \relax }{figure.caption.31}{}}
\citation{alexnet}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Considerazioni finali}{76}{subsection.5.3.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Si noti che tra tutti i training quello in cui si sono ottenuti i risultati in media migliori per il test è quello con gli iperparametri pari a quelli della seconda riga.\relax }}{77}{table.caption.32}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusioni}{78}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{Roc}
\newlabel{fig:snap1}{{6.1a}{80}{\relax }{figure.caption.33}{}}
\newlabel{sub@fig:snap1}{{a}{80}{\relax }{figure.caption.33}{}}
\newlabel{fig:snap2}{{6.1b}{80}{\relax }{figure.caption.33}{}}
\newlabel{sub@fig:snap2}{{b}{80}{\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Confronto della caratteristica ROC tra il sistema per la rilevazione della polmonite senza applicare le modifiche al set di training (a) e quella del sistema allenato sul set ampliato (b). Il codice di realizzazione può essere visto nel Code Listing 7.1. \relax }}{80}{figure.caption.33}\protected@file@percent }
\newlabel{fig:fig}{{6.1}{80}{Confronto della caratteristica ROC tra il sistema per la rilevazione della polmonite senza applicare le modifiche al set di training (a) e quella del sistema allenato sul set ampliato (b). Il codice di realizzazione può essere visto nel Code Listing 7.1. \relax }{figure.caption.33}{}}
\newlabel{fig:snap1}{{6.2a}{80}{\relax }{figure.caption.34}{}}
\newlabel{sub@fig:snap1}{{a}{80}{\relax }{figure.caption.34}{}}
\newlabel{fig:snap2}{{6.2b}{80}{\relax }{figure.caption.34}{}}
\newlabel{sub@fig:snap2}{{b}{80}{\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Confronto tra la caratteristica ROC del modello \emph  {2.} con rumore gaussiano e del modello \emph  {3.} per il dataset delle RM. (a) mostra una AUC di 0.96, (b) dello 0.99. Il codice di realizzazione può essere visto nel Code Listing 7.2. \relax }}{80}{figure.caption.34}\protected@file@percent }
\newlabel{fig:fig}{{6.2}{80}{Confronto tra la caratteristica ROC del modello \emph {2.} con rumore gaussiano e del modello \emph {3.} per il dataset delle RM. (a) mostra una AUC di 0.96, (b) dello 0.99. Il codice di realizzazione può essere visto nel Code Listing 7.2. \relax }{figure.caption.34}{}}
\citation{dspneum}
\citation{dspneum}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Codice}{81}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.1}Esempio di implementazione di una CNN per la classificazione di raggi-X.~\cite  {dspneum}}{81}{lstlisting.7.1}\protected@file@percent }
\citation{dsbrain}
\citation{dsbrain}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7.2}Esempio di implementazione di AlexNet per la classificazione di RM con l'aggiunta di rumore al set di training.~\cite  {dsbrain}}{84}{lstlisting.7.2}\protected@file@percent }
\bibstyle{ieeetr}
\bibdata{bibliografia}
\bibcite{ann}{1}
\bibcite{learning}{2}
\bibcite{ml}{3}
\bibcite{class}{4}
\bibcite{prob}{5}
\bibcite{img_learning}{6}
\bibcite{reti}{7}
\bibcite{neuron}{8}
\bibcite{dl}{9}
\bibcite{dim}{10}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Bibliografia}{89}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{dnn}{11}
\bibcite{tesi}{12}
\bibcite{ofuf}{13}
\bibcite{classdef}{14}
\bibcite{cnn}{15}
\bibcite{feature}{16}
\bibcite{sparse}{17}
\bibcite{max-pool}{18}
\bibcite{grad}{19}
\bibcite{cnn2}{20}
\bibcite{lib}{21}
\bibcite{keras}{22}
\bibcite{tf}{23}
\bibcite{jn}{24}
\bibcite{dspneum}{25}
\bibcite{augpneum}{26}
\bibcite{dsbrain}{27}
\bibcite{dropout}{28}
\bibcite{norm}{29}
\bibcite{alexnet}{30}
\bibcite{effnet}{31}
\bibcite{mobilenet}{32}
\bibcite{gaussnoise}{33}
\bibcite{Roc}{34}
\gdef \@abspage@last{93}
